# Identification of Acoustic Movement Signals

This code repository contains the data and code used to classify signals from a mic-based movement sensor. Recordings were taken of a womans abdomen and of pressing and tapping motions which mimic kicking and full body movements of a fetus. Basic signal processing is used to extract 0.03s 'events' in these recordings, and a 1D wavelet transform is applied to create scalograms of these signal chunks. The pretrained ResNet 50 model is loaded in PyTorch, and the final linear layer is retrained to categorise the three signal types. It achieves accuracies of ~0.95 after 15 epochs, with a training and test batch sizes of 60 and 20 respectively.

This code is a prototype to assess the feasibility of predicting a mother's risk of stillbirth from wearable sensor readings of her stomach. The proposed system would use fibre bragg gratings to detect fetal movements. The ML model in this repo would be used to categorise the fetal movements by type, and a further model would assess the risk of stillbirth suggested by the detected pattern of movements. 
